
| epoch   1 |    10/   90 batches | lr 0.001000 | 130.43 ms | loss 0.15948
| epoch   1 |    20/   90 batches | lr 0.001000 | 123.20 ms | loss 0.14778
| epoch   1 |    30/   90 batches | lr 0.001000 | 126.62 ms | loss 0.09869
| epoch   1 |    40/   90 batches | lr 0.001000 | 146.44 ms | loss 0.09270
| epoch   1 |    50/   90 batches | lr 0.001000 | 139.09 ms | loss 0.07453
| epoch   1 |    60/   90 batches | lr 0.001000 | 126.40 ms | loss 0.05779
| epoch   1 |    70/   90 batches | lr 0.001000 | 116.59 ms | loss 0.08641
| epoch   1 |    80/   90 batches | lr 0.001000 | 116.87 ms | loss 0.07874
| epoch   1 |    90/   90 batches | lr 0.001000 | 110.76 ms | loss 0.10814
data_source shape: torch.Size([5784, 2, 20, 36])
output shape: torch.Size([20, 1, 36])
output[[0]].shape: torch.Size([1, 1, 36])
output[:-1].shape: torch.Size([19, 1, 36])
truth shape: torch.Size([5803, 36])
test_result shape: torch.Size([5803, 36])
output truth shape: (5803, 36)
output test_result shape: (5803, 36)
test_result[0].shape, type (36,) float64
test_result.shape, type (5803, 36) float64
loss shape:  (5803, 36)
output_df shape: (5803, 108)
---------------------------------
start SVM
---------------------------------
exception calling callback for <Future at 0x1c323022408 state=finished raised TerminatedWorkerError>
Traceback (most recent call last):
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\externals\loky\_base.py", line 625, in _invoke_callbacks
    callback(self)
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\parallel.py", line 359, in __call__
    self.parallel.dispatch_next()
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\parallel.py", line 794, in dispatch_next
    if not self.dispatch_one_batch(self._original_iterator):
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\parallel.py", line 861, in dispatch_one_batch
    self._dispatch(tasks)
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\parallel.py", line 779, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\_parallel_backends.py", line 531, in apply_async
    future = self._workers.submit(SafeFunction(func))
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\externals\loky\reusable_executor.py", line 178, in submit
    fn, *args, **kwargs)
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\externals\loky\process_executor.py", line 1115, in submit
    raise self._flags.broken
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.
Traceback (most recent call last):
  File "train.py", line 150, in <module>
    main(args)
  File "train.py", line 115, in main
    val_loss = plot_and_loss(model, val_data, epoch, criterion, input_window, scaler, args.dim, labels)
  File "D:\PythonProject\Time_series_anomaly_detection\utils\plot_and_loss.py", line 133, in plot_and_loss
    clf = svm_c(loss_value, labels)
  File "D:\PythonProject\Time_series_anomaly_detection\utils\plot_and_loss.py", line 193, in svm_c
    clf = grid.fit(x_train, y_train)
  File "D:\miniconda\envs\pytorch\lib\site-packages\sklearn\model_selection\_search.py", line 891, in fit
    self._run_search(evaluate_candidates)
  File "D:\miniconda\envs\pytorch\lib\site-packages\sklearn\model_selection\_search.py", line 1768, in _run_search
    self.param_distributions, self.n_iter, random_state=self.random_state
  File "D:\miniconda\envs\pytorch\lib\site-packages\sklearn\model_selection\_search.py", line 851, in evaluate_candidates
    enumerate(candidate_params), enumerate(cv.split(X, y, groups))
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\parallel.py", line 1056, in __call__
    self.retrieve()
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "D:\miniconda\envs\pytorch\lib\concurrent\futures\_base.py", line 435, in result
    return self.__get_result()
  File "D:\miniconda\envs\pytorch\lib\concurrent\futures\_base.py", line 384, in __get_result
    raise self._exception
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\externals\loky\_base.py", line 625, in _invoke_callbacks
    callback(self)
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\parallel.py", line 359, in __call__
    self.parallel.dispatch_next()
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\parallel.py", line 794, in dispatch_next
    if not self.dispatch_one_batch(self._original_iterator):
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\parallel.py", line 861, in dispatch_one_batch
    self._dispatch(tasks)
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\parallel.py", line 779, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\_parallel_backends.py", line 531, in apply_async
    future = self._workers.submit(SafeFunction(func))
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\externals\loky\reusable_executor.py", line 178, in submit
    fn, *args, **kwargs)
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\externals\loky\process_executor.py", line 1115, in submit
    raise self._flags.broken
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.