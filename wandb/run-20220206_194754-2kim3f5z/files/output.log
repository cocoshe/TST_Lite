
D:\PythonProject\Time_series_anomaly_detection\weights\2022_02_06 19_48_01
train.py:86: DtypeWarning: Columns (1,2,3) have mixed types.Specify dtype option on import or set low_memory=False.
  train_data, val_data, timestamp, scaler = get_data(args, input_window, output_window, device=device)
find port id.
find polution id.
find company id.
         company_id                port_id polution_id                 date  concentration    amount
0    17280000089583  64000000000600100000       w00000    1/1/2020 00:00:00          66.25   870.000
1    17280000089583  64000000000600100000       w00000    2/1/2020 00:00:00          73.18  1758.000
2    17280000089583  64000000000600100000       w00000    3/1/2020 00:00:00          79.95  1918.000
3    17280000089583  64000000000600100000       w00000    4/1/2020 00:00:00          69.91  1678.000
4    17280000089583  64000000000600100000       w00000    5/1/2020 00:00:00            NaN    74.000
..              ...                    ...         ...                  ...            ...       ...
670  17280000089583  64000000000600100000       w00000  25/11/2021 00:00:00          41.70  3600.563
671  17280000089583  64000000000600100000       w00000  26/11/2021 00:00:00          35.30  1525.746
672  17280000089583  64000000000600100000       w00000  27/11/2021 00:00:00           0.00     0.000
673  17280000089583  64000000000600100000       w00000  28/11/2021 00:00:00          39.80   858.972
674  17280000089583  64000000000600100000       w00000  29/11/2021 00:00:00          41.90  3616.834
[675 rows x 6 columns]
dim_name:  concentration
-----------------------------------------------
series:  0      66.25
1      73.18
2      79.95
3      69.91
4       0.00
       ...
670    41.70
671    35.30
672     0.00
673    39.80
674    41.90
Name: concentration, Length: 675, dtype: float64
series.shape:  (675,)
-----------------------------------------------
D:\PythonProject\Time_series_anomaly_detection\utils\data_prepare.py:19: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\torch\csrc\utils\tensor_new.cpp:201.)
  return torch.FloatTensor(inout_seq)
| epoch   1 |    10/   10 batches | lr 0.006000 | 325.62 ms | loss 1.53723
-----------------------------------------------------------------------------------------
| end of epoch   1 | time:  3.95s | valid loss 0.15381
-----------------------------------------------------------------------------------------
save successfully
| epoch   2 |    10/   10 batches | lr 0.006000 | 328.60 ms | loss 0.07329
-----------------------------------------------------------------------------------------
| end of epoch   2 | time:  4.04s | valid loss 0.04214
-----------------------------------------------------------------------------------------
save successfully
| epoch   3 |    10/   10 batches | lr 0.006000 | 319.20 ms | loss 0.10785
-----------------------------------------------------------------------------------------
| end of epoch   3 | time:  3.87s | valid loss 0.13221
-----------------------------------------------------------------------------------------
| epoch   4 |    10/   10 batches | lr 0.006000 | 330.82 ms | loss 0.08680
-----------------------------------------------------------------------------------------
| end of epoch   4 | time:  4.06s | valid loss 0.04577
-----------------------------------------------------------------------------------------
| epoch   5 |    10/   10 batches | lr 0.006000 | 338.24 ms | loss 0.05616
-----------------------------------------------------------------------------------------
| end of epoch   5 | time:  4.14s | valid loss 0.04587
-----------------------------------------------------------------------------------------
| epoch   6 |    10/   10 batches | lr 0.006000 | 338.99 ms | loss 0.06624
-----------------------------------------------------------------------------------------
| end of epoch   6 | time:  4.16s | valid loss 0.05845
-----------------------------------------------------------------------------------------
| epoch   7 |    10/   10 batches | lr 0.006000 | 356.56 ms | loss 0.05727
-----------------------------------------------------------------------------------------
| end of epoch   7 | time:  4.39s | valid loss 0.05981
-----------------------------------------------------------------------------------------
| epoch   8 |    10/   10 batches | lr 0.006000 | 376.34 ms | loss 0.05866
-----------------------------------------------------------------------------------------
| end of epoch   8 | time:  4.62s | valid loss 0.06551
-----------------------------------------------------------------------------------------
| epoch   9 |    10/   10 batches | lr 0.005700 | 421.54 ms | loss 0.05619
-----------------------------------------------------------------------------------------
| end of epoch   9 | time:  5.17s | valid loss 0.03679
-----------------------------------------------------------------------------------------
save successfully
| epoch  10 |    10/   10 batches | lr 0.005700 | 379.86 ms | loss 0.05377
loss shape:  (673,)
-----------------------------------------------------------------------------------------
| end of epoch  10 | time:  7.02s | valid loss 0.07221
-----------------------------------------------------------------------------------------
| epoch  11 |    10/   10 batches | lr 0.005700 | 372.96 ms | loss 0.05546
-----------------------------------------------------------------------------------------
| end of epoch  11 | time:  4.54s | valid loss 0.03392
-----------------------------------------------------------------------------------------
save successfully
| epoch  12 |    10/   10 batches | lr 0.005700 | 375.79 ms | loss 0.05299
-----------------------------------------------------------------------------------------
| end of epoch  12 | time:  4.61s | valid loss 0.06310
-----------------------------------------------------------------------------------------
| epoch  13 |    10/   10 batches | lr 0.005700 | 398.07 ms | loss 0.05195
-----------------------------------------------------------------------------------------
| end of epoch  13 | time:  4.90s | valid loss 0.03614
-----------------------------------------------------------------------------------------
| epoch  14 |    10/   10 batches | lr 0.005700 | 369.76 ms | loss 0.05007
-----------------------------------------------------------------------------------------
| end of epoch  14 | time:  4.50s | valid loss 0.06425
-----------------------------------------------------------------------------------------
| epoch  15 |    10/   10 batches | lr 0.005700 | 398.07 ms | loss 0.05075
-----------------------------------------------------------------------------------------
| end of epoch  15 | time:  4.74s | valid loss 0.03286
-----------------------------------------------------------------------------------------
save successfully
| epoch  16 |    10/   10 batches | lr 0.005700 | 359.41 ms | loss 0.05021
-----------------------------------------------------------------------------------------
| end of epoch  16 | time:  4.39s | valid loss 0.06382
-----------------------------------------------------------------------------------------
| epoch  17 |    10/   10 batches | lr 0.005415 | 366.71 ms | loss 0.04954
-----------------------------------------------------------------------------------------
| end of epoch  17 | time:  4.64s | valid loss 0.03725
-----------------------------------------------------------------------------------------
| epoch  18 |    10/   10 batches | lr 0.005415 | 355.68 ms | loss 0.04790
-----------------------------------------------------------------------------------------
| end of epoch  18 | time:  4.34s | valid loss 0.06038
-----------------------------------------------------------------------------------------
| epoch  19 |    10/   10 batches | lr 0.005415 | 345.29 ms | loss 0.04924
-----------------------------------------------------------------------------------------
| end of epoch  19 | time:  4.22s | valid loss 0.03561
-----------------------------------------------------------------------------------------
| epoch  20 |    10/   10 batches | lr 0.005415 | 335.72 ms | loss 0.04638
loss shape:  (673,)
-----------------------------------------------------------------------------------------
| end of epoch  20 | time:  6.26s | valid loss 0.05843
-----------------------------------------------------------------------------------------
| epoch  21 |    10/   10 batches | lr 0.005415 | 357.38 ms | loss 0.04755
-----------------------------------------------------------------------------------------
| end of epoch  21 | time:  4.31s | valid loss 0.03709
-----------------------------------------------------------------------------------------
| epoch  22 |    10/   10 batches | lr 0.005415 | 380.10 ms | loss 0.04438
-----------------------------------------------------------------------------------------
| end of epoch  22 | time:  4.63s | valid loss 0.05305
-----------------------------------------------------------------------------------------
| epoch  23 |    10/   10 batches | lr 0.005415 | 356.80 ms | loss 0.04624
-----------------------------------------------------------------------------------------
| end of epoch  23 | time:  4.34s | valid loss 0.03249
-----------------------------------------------------------------------------------------
save successfully
| epoch  24 |    10/   10 batches | lr 0.005415 | 336.23 ms | loss 0.04344
-----------------------------------------------------------------------------------------
| end of epoch  24 | time:  4.08s | valid loss 0.04683
-----------------------------------------------------------------------------------------
| epoch  25 |    10/   10 batches | lr 0.005144 | 327.19 ms | loss 0.04525
-----------------------------------------------------------------------------------------
| end of epoch  25 | time:  3.98s | valid loss 0.03910
-----------------------------------------------------------------------------------------
| epoch  26 |    10/   10 batches | lr 0.005144 | 331.52 ms | loss 0.04254
-----------------------------------------------------------------------------------------
| end of epoch  26 | time:  4.12s | valid loss 0.03890
-----------------------------------------------------------------------------------------
| epoch  27 |    10/   10 batches | lr 0.005144 | 388.46 ms | loss 0.04095
-----------------------------------------------------------------------------------------
| end of epoch  27 | time:  4.71s | valid loss 0.04226
-----------------------------------------------------------------------------------------
| epoch  28 |    10/   10 batches | lr 0.005144 | 346.64 ms | loss 0.04083
-----------------------------------------------------------------------------------------
| end of epoch  28 | time:  4.25s | valid loss 0.03538
-----------------------------------------------------------------------------------------
| epoch  29 |    10/   10 batches | lr 0.005144 | 352.89 ms | loss 0.03691
-----------------------------------------------------------------------------------------
| end of epoch  29 | time:  4.25s | valid loss 0.03225
-----------------------------------------------------------------------------------------
save successfully
| epoch  30 |    10/   10 batches | lr 0.005144 | 360.85 ms | loss 0.03118
loss shape:  (673,)
-----------------------------------------------------------------------------------------
| end of epoch  30 | time:  6.90s | valid loss 0.01970
-----------------------------------------------------------------------------------------
save successfully
| epoch  31 |    10/   10 batches | lr 0.005144 | 354.87 ms | loss 0.03792
-----------------------------------------------------------------------------------------
| end of epoch  31 | time:  4.26s | valid loss 0.03035
-----------------------------------------------------------------------------------------
| epoch  32 |    10/   10 batches | lr 0.005144 | 379.22 ms | loss 0.02845
-----------------------------------------------------------------------------------------
| end of epoch  32 | time:  4.63s | valid loss 0.01829
-----------------------------------------------------------------------------------------
save successfully
| epoch  33 |    10/   10 batches | lr 0.004887 | 351.61 ms | loss 0.02828
-----------------------------------------------------------------------------------------
| end of epoch  33 | time:  4.34s | valid loss 0.03002
-----------------------------------------------------------------------------------------
| epoch  34 |    10/   10 batches | lr 0.004887 | 366.33 ms | loss 0.02261
-----------------------------------------------------------------------------------------
| end of epoch  34 | time:  4.43s | valid loss 0.02269
-----------------------------------------------------------------------------------------
| epoch  35 |    10/   10 batches | lr 0.004887 | 364.14 ms | loss 0.01964
-----------------------------------------------------------------------------------------
| end of epoch  35 | time:  4.39s | valid loss 0.01862
-----------------------------------------------------------------------------------------
| epoch  36 |    10/   10 batches | lr 0.004887 | 362.66 ms | loss 0.02011
-----------------------------------------------------------------------------------------
| end of epoch  36 | time:  4.38s | valid loss 0.02403
-----------------------------------------------------------------------------------------
| epoch  37 |    10/   10 batches | lr 0.004887 | 332.56 ms | loss 0.01902
-----------------------------------------------------------------------------------------
| end of epoch  37 | time:  4.09s | valid loss 0.02517
-----------------------------------------------------------------------------------------
| epoch  38 |    10/   10 batches | lr 0.004887 | 334.42 ms | loss 0.01870
-----------------------------------------------------------------------------------------
| end of epoch  38 | time:  4.05s | valid loss 0.02403
-----------------------------------------------------------------------------------------
| epoch  39 |    10/   10 batches | lr 0.004887 | 342.99 ms | loss 0.01836
-----------------------------------------------------------------------------------------
| end of epoch  39 | time:  4.15s | valid loss 0.02180
-----------------------------------------------------------------------------------------
| epoch  40 |    10/   10 batches | lr 0.004887 | 336.24 ms | loss 0.01799
loss shape:  (673,)
-----------------------------------------------------------------------------------------
| end of epoch  40 | time:  6.50s | valid loss 0.02141
-----------------------------------------------------------------------------------------
| epoch  41 |    10/   10 batches | lr 0.004643 | 340.22 ms | loss 0.01778
-----------------------------------------------------------------------------------------
| end of epoch  41 | time:  4.13s | valid loss 0.01831
-----------------------------------------------------------------------------------------
| epoch  42 |    10/   10 batches | lr 0.004643 | 339.53 ms | loss 0.01714
-----------------------------------------------------------------------------------------
| end of epoch  42 | time:  4.16s | valid loss 0.01681
-----------------------------------------------------------------------------------------
save successfully
| epoch  43 |    10/   10 batches | lr 0.004643 | 334.92 ms | loss 0.01744
-----------------------------------------------------------------------------------------
| end of epoch  43 | time:  4.07s | valid loss 0.01598
-----------------------------------------------------------------------------------------
save successfully
| epoch  44 |    10/   10 batches | lr 0.004643 | 335.30 ms | loss 0.01846
-----------------------------------------------------------------------------------------
| end of epoch  44 | time:  4.04s | valid loss 0.01701
-----------------------------------------------------------------------------------------
| epoch  45 |    10/   10 batches | lr 0.004643 | 341.58 ms | loss 0.01823
-----------------------------------------------------------------------------------------
| end of epoch  45 | time:  4.13s | valid loss 0.02199
-----------------------------------------------------------------------------------------
| epoch  46 |    10/   10 batches | lr 0.004643 | 341.82 ms | loss 0.01788
-----------------------------------------------------------------------------------------
| end of epoch  46 | time:  4.13s | valid loss 0.02311
-----------------------------------------------------------------------------------------
| epoch  47 |    10/   10 batches | lr 0.004643 | 341.77 ms | loss 0.01756
-----------------------------------------------------------------------------------------
| end of epoch  47 | time:  4.21s | valid loss 0.02231
-----------------------------------------------------------------------------------------
| epoch  48 |    10/   10 batches | lr 0.004643 | 355.35 ms | loss 0.01739
-----------------------------------------------------------------------------------------
| end of epoch  48 | time:  4.30s | valid loss 0.02319
-----------------------------------------------------------------------------------------
| epoch  49 |    10/   10 batches | lr 0.004411 | 352.28 ms | loss 0.01741
-----------------------------------------------------------------------------------------
| end of epoch  49 | time:  4.27s | valid loss 0.02212
-----------------------------------------------------------------------------------------
| epoch  50 |    10/   10 batches | lr 0.004411 | 347.57 ms | loss 0.01710
loss shape:  (673,)
-----------------------------------------------------------------------------------------
| end of epoch  50 | time:  6.55s | valid loss 0.02307
-----------------------------------------------------------------------------------------
| epoch  51 |    10/   10 batches | lr 0.004411 | 361.67 ms | loss 0.01721
-----------------------------------------------------------------------------------------
| end of epoch  51 | time:  4.37s | valid loss 0.02288
-----------------------------------------------------------------------------------------
| epoch  52 |    10/   10 batches | lr 0.004411 | 353.96 ms | loss 0.01700
-----------------------------------------------------------------------------------------
| end of epoch  52 | time:  4.37s | valid loss 0.02167
-----------------------------------------------------------------------------------------
| epoch  53 |    10/   10 batches | lr 0.004411 | 350.19 ms | loss 0.01695
-----------------------------------------------------------------------------------------
| end of epoch  53 | time:  4.33s | valid loss 0.02171
-----------------------------------------------------------------------------------------
| epoch  54 |    10/   10 batches | lr 0.004411 | 343.60 ms | loss 0.01677
-----------------------------------------------------------------------------------------
| end of epoch  54 | time:  4.34s | valid loss 0.01862
-----------------------------------------------------------------------------------------
| epoch  55 |    10/   10 batches | lr 0.004411 | 372.33 ms | loss 0.01659
-----------------------------------------------------------------------------------------
| end of epoch  55 | time:  4.44s | valid loss 0.01816
-----------------------------------------------------------------------------------------
| epoch  56 |    10/   10 batches | lr 0.004411 | 361.17 ms | loss 0.01653
-----------------------------------------------------------------------------------------
| end of epoch  56 | time:  4.36s | valid loss 0.01661
-----------------------------------------------------------------------------------------
| epoch  57 |    10/   10 batches | lr 0.004190 | 347.80 ms | loss 0.01664
-----------------------------------------------------------------------------------------
| end of epoch  57 | time:  4.24s | valid loss 0.01590
-----------------------------------------------------------------------------------------
save successfully
| epoch  58 |    10/   10 batches | lr 0.004190 | 361.32 ms | loss 0.01687
-----------------------------------------------------------------------------------------
| end of epoch  58 | time:  4.37s | valid loss 0.01550
-----------------------------------------------------------------------------------------
save successfully
| epoch  59 |    10/   10 batches | lr 0.004190 | 352.48 ms | loss 0.01716
-----------------------------------------------------------------------------------------
| end of epoch  59 | time:  4.28s | valid loss 0.01652
-----------------------------------------------------------------------------------------
| epoch  60 |    10/   10 batches | lr 0.004190 | 416.03 ms | loss 0.01696
loss shape:  (673,)
-----------------------------------------------------------------------------------------
| end of epoch  60 | time:  7.48s | valid loss 0.01893
-----------------------------------------------------------------------------------------
| epoch  61 |    10/   10 batches | lr 0.004190 | 375.16 ms | loss 0.01639
-----------------------------------------------------------------------------------------
| end of epoch  61 | time:  4.59s | valid loss 0.01915
-----------------------------------------------------------------------------------------
| epoch  62 |    10/   10 batches | lr 0.004190 | 371.52 ms | loss 0.01638
-----------------------------------------------------------------------------------------
| end of epoch  62 | time:  4.48s | valid loss 0.01953
-----------------------------------------------------------------------------------------
| epoch  63 |    10/   10 batches | lr 0.004190 | 378.55 ms | loss 0.01638
-----------------------------------------------------------------------------------------
| end of epoch  63 | time:  4.65s | valid loss 0.02033
-----------------------------------------------------------------------------------------
| epoch  64 |    10/   10 batches | lr 0.004190 | 383.89 ms | loss 0.01655
-----------------------------------------------------------------------------------------
| end of epoch  64 | time:  4.56s | valid loss 0.02091
-----------------------------------------------------------------------------------------
| epoch  65 |    10/   10 batches | lr 0.003981 | 356.65 ms | loss 0.01643
-----------------------------------------------------------------------------------------
| end of epoch  65 | time:  4.32s | valid loss 0.02174
-----------------------------------------------------------------------------------------
| epoch  66 |    10/   10 batches | lr 0.003981 | 387.04 ms | loss 0.01687
-----------------------------------------------------------------------------------------
| end of epoch  66 | time:  4.63s | valid loss 0.02291
-----------------------------------------------------------------------------------------
| epoch  67 |    10/   10 batches | lr 0.003981 | 375.56 ms | loss 0.01683
-----------------------------------------------------------------------------------------
| end of epoch  67 | time:  4.56s | valid loss 0.02031
-----------------------------------------------------------------------------------------
| epoch  68 |    10/   10 batches | lr 0.003981 | 369.67 ms | loss 0.01658
-----------------------------------------------------------------------------------------
| end of epoch  68 | time:  4.59s | valid loss 0.02072
-----------------------------------------------------------------------------------------
| epoch  69 |    10/   10 batches | lr 0.003981 | 363.84 ms | loss 0.01657
-----------------------------------------------------------------------------------------
| end of epoch  69 | time:  4.44s | valid loss 0.01922
-----------------------------------------------------------------------------------------
| epoch  70 |    10/   10 batches | lr 0.003981 | 366.75 ms | loss 0.01631
loss shape:  (673,)
-----------------------------------------------------------------------------------------
| end of epoch  70 | time:  7.01s | valid loss 0.01982
-----------------------------------------------------------------------------------------
| epoch  71 |    10/   10 batches | lr 0.003981 | 389.79 ms | loss 0.01641
-----------------------------------------------------------------------------------------
| end of epoch  71 | time:  4.75s | valid loss 0.01978
-----------------------------------------------------------------------------------------
| epoch  72 |    10/   10 batches | lr 0.003981 | 380.78 ms | loss 0.01625
-----------------------------------------------------------------------------------------
| end of epoch  72 | time:  4.60s | valid loss 0.01973
-----------------------------------------------------------------------------------------
| epoch  73 |    10/   10 batches | lr 0.003781 | 375.99 ms | loss 0.01657
-----------------------------------------------------------------------------------------
| end of epoch  73 | time:  4.48s | valid loss 0.02100
-----------------------------------------------------------------------------------------
| epoch  74 |    10/   10 batches | lr 0.003781 | 378.99 ms | loss 0.01653
-----------------------------------------------------------------------------------------
| end of epoch  74 | time:  4.82s | valid loss 0.01828
-----------------------------------------------------------------------------------------
| epoch  75 |    10/   10 batches | lr 0.003781 | 387.68 ms | loss 0.01592
-----------------------------------------------------------------------------------------
| end of epoch  75 | time:  4.62s | valid loss 0.01789
-----------------------------------------------------------------------------------------
| epoch  76 |    10/   10 batches | lr 0.003781 | 362.49 ms | loss 0.01630
-----------------------------------------------------------------------------------------
| end of epoch  76 | time:  4.39s | valid loss 0.01810
-----------------------------------------------------------------------------------------
| epoch  77 |    10/   10 batches | lr 0.003781 | 369.32 ms | loss 0.01582
-----------------------------------------------------------------------------------------
| end of epoch  77 | time:  4.42s | valid loss 0.01697
-----------------------------------------------------------------------------------------
Traceback (most recent call last):
  File "train.py", line 139, in <module>
    main(args)
  File "train.py", line 101, in main
    train(train_data, input_window, model, optimizer, criterion, scheduler, epoch, batch_size)
  File "D:\PythonProject\Time_series_anomaly_detection\utils\train.py", line 21, in train
    loss.backward()
  File "D:\miniconda\envs\pytorch\lib\site-packages\torch\_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "D:\miniconda\envs\pytorch\lib\site-packages\torch\autograd\__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
  File "D:\miniconda\envs\pytorch\lib\site-packages\wandb\wandb_torch.py", line 282, in <lambda>
    handle = var.register_hook(lambda grad: _callback(grad, log_track))
  File "D:\miniconda\envs\pytorch\lib\site-packages\wandb\wandb_torch.py", line 277, in _callback
    def _callback(grad, log_track):
KeyboardInterrupt