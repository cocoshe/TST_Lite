D:\PythonProject\Time_series_anomaly_detection\weights\2022_02_11 19_48_31
       company_id       port_id polution_id                 date  concentration    amount
0    1.728000e+13  6.400000e+19      w00000    1/1/2021 00:00:00           29.9  2047.590
1    1.728000e+13  6.400000e+19      w00000    2/1/2021 00:00:00           30.6  2648.000
2    1.728000e+13  6.400000e+19      w00000    3/1/2021 00:00:00           24.8  2142.000
3    1.728000e+13  6.400000e+19      w00000    4/1/2021 00:00:00           37.2  3218.000
4    1.728000e+13  6.400000e+19      w00000    5/1/2021 00:00:00           21.0  1818.000
..            ...           ...         ...                  ...            ...       ...
304  1.728000e+13  6.400000e+19      w00000  25/11/2021 00:00:00           41.7  3600.563
305  1.728000e+13  6.400000e+19      w00000  26/11/2021 00:00:00           35.3  1525.746
306  1.728000e+13  6.400000e+19      w00000  27/11/2021 00:00:00            0.0     0.000
307  1.728000e+13  6.400000e+19      w00000  28/11/2021 00:00:00           39.8   858.972
308  1.728000e+13  6.400000e+19      w00000  29/11/2021 00:00:00           41.9  3616.834
[309 rows x 6 columns]
-----------------------------------------------
series:  0      29.9
1      30.6
2      24.8
3      37.2
4      21.0
       ...
304    41.7
305    35.3
306     0.0
307    39.8
308    41.9
Name: concentration, Length: 309, dtype: float64
series.shape:  (309,)
-----------------------------------------------
D:\PythonProject\Time_series_anomaly_detection\utils\data_prepare.py:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\torch\csrc\utils\tensor_new.cpp:201.)
  return torch.FloatTensor(inout_seq)
-----------------------------------------------------------------------------------------
| end of epoch   1 | time:  2.15s | valid loss 0.18281
-----------------------------------------------------------------------------------------
save successfully
-----------------------------------------------------------------------------------------
| end of epoch   2 | time:  1.73s | valid loss 0.24521
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   3 | time:  1.80s | valid loss 0.03295
-----------------------------------------------------------------------------------------
save successfully
-----------------------------------------------------------------------------------------
| end of epoch   4 | time:  1.71s | valid loss 0.05276
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   5 | time:  1.70s | valid loss 0.03617
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   6 | time:  1.74s | valid loss 0.04592
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   7 | time:  1.74s | valid loss 0.04222
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch   8 | time:  1.71s | valid loss 0.02896
-----------------------------------------------------------------------------------------
save successfully
-----------------------------------------------------------------------------------------
| end of epoch   9 | time:  1.76s | valid loss 0.02767
-----------------------------------------------------------------------------------------
save successfully
loss shape:  (307,)
-----------------------------------------------------------------------------------------
| end of epoch  10 | time:  3.27s | valid loss 0.08208
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  11 | time:  1.77s | valid loss 0.04454
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  12 | time:  1.74s | valid loss 0.02831
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  13 | time:  1.84s | valid loss 0.04190
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  14 | time:  1.74s | valid loss 0.03416
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  15 | time:  1.89s | valid loss 0.02730
-----------------------------------------------------------------------------------------
save successfully
-----------------------------------------------------------------------------------------
| end of epoch  16 | time:  2.48s | valid loss 0.07541
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  17 | time:  1.87s | valid loss 0.04252
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  18 | time:  1.82s | valid loss 0.02770
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  19 | time:  1.85s | valid loss 0.07156
-----------------------------------------------------------------------------------------
loss shape:  (307,)
-----------------------------------------------------------------------------------------
| end of epoch  20 | time:  3.49s | valid loss 0.04135
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  21 | time:  1.78s | valid loss 0.02955
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  22 | time:  1.95s | valid loss 0.03223
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  23 | time:  1.98s | valid loss 0.02952
-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------
| end of epoch  24 | time:  1.82s | valid loss 0.02789
-----------------------------------------------------------------------------------------
Traceback (most recent call last):
  File "train.py", line 139, in <module>
    main(args)
  File "train.py", line 101, in main
    train(train_data, input_window, model, optimizer, criterion, scheduler, epoch, batch_size)
  File "D:\PythonProject\Time_series_anomaly_detection\utils\train.py", line 19, in train
    output = model(data)
  File "D:\miniconda\envs\pytorch\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "D:\PythonProject\Time_series_anomaly_detection\model\Transformer.py", line 35, in forward
    output = self.transformer_encoder(src, self.src_mask)  # , self.src_mask)
  File "D:\miniconda\envs\pytorch\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "D:\miniconda\envs\pytorch\lib\site-packages\torch\nn\modules\transformer.py", line 198, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)
  File "D:\miniconda\envs\pytorch\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "D:\miniconda\envs\pytorch\lib\site-packages\torch\nn\modules\transformer.py", line 340, in forward
    x = self.norm2(x + self._ff_block(x))
  File "D:\miniconda\envs\pytorch\lib\site-packages\torch\nn\modules\transformer.py", line 355, in _ff_block
    x = self.linear2(self.dropout(self.activation(self.linear1(x))))
  File "D:\miniconda\envs\pytorch\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "D:\miniconda\envs\pytorch\lib\site-packages\torch\nn\modules\dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "D:\miniconda\envs\pytorch\lib\site-packages\torch\nn\functional.py", line 1169, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
KeyboardInterrupt