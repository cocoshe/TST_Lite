
| epoch   1 |    10/   90 batches | lr 0.001000 | 131.20 ms | loss 0.16067
| epoch   1 |    20/   90 batches | lr 0.001000 | 122.72 ms | loss 0.14721
| epoch   1 |    30/   90 batches | lr 0.001000 | 118.42 ms | loss 0.09241
| epoch   1 |    40/   90 batches | lr 0.001000 | 113.48 ms | loss 0.08437
| epoch   1 |    50/   90 batches | lr 0.001000 | 118.68 ms | loss 0.07097
| epoch   1 |    60/   90 batches | lr 0.001000 | 154.64 ms | loss 0.05633
| epoch   1 |    70/   90 batches | lr 0.001000 | 117.71 ms | loss 0.08519
| epoch   1 |    80/   90 batches | lr 0.001000 | 135.89 ms | loss 0.07545
| epoch   1 |    90/   90 batches | lr 0.001000 | 105.58 ms | loss 0.10660
data_source shape: torch.Size([5784, 2, 20, 36])
output shape: torch.Size([20, 1, 36])
output[[0]].shape: torch.Size([1, 1, 36])
output[:-1].shape: torch.Size([19, 1, 36])
truth shape: torch.Size([5803, 36])
test_result shape: torch.Size([5803, 36])
output truth shape: (5803, 36)
output test_result shape: (5803, 36)
test_result[0].shape, type (36,) float64
test_result.shape, type (5803, 36) float64
loss shape:  (5803, 36)
output_df shape: (5803, 108)
---------------------------------
start SVM
---------------------------------
精度为0.9875947622329428
precision:  1.0  recall:  0.49295774647887325  acc:  0.9937963122522833  f1:  0.660377358490566
混淆矩阵:
 [[5732    0]
 [  36   35]]
-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 43.88s | valid loss 9.18026
-----------------------------------------------------------------------------------------
save successfully
| epoch   2 |    10/   90 batches | lr 0.001000 | 121.21 ms | loss 0.06085
| epoch   2 |    20/   90 batches | lr 0.001000 | 116.66 ms | loss 0.06256
| epoch   2 |    30/   90 batches | lr 0.001000 | 115.35 ms | loss 0.04730
| epoch   2 |    40/   90 batches | lr 0.001000 | 114.19 ms | loss 0.04787
| epoch   2 |    50/   90 batches | lr 0.001000 | 112.35 ms | loss 0.04137
| epoch   2 |    60/   90 batches | lr 0.001000 | 113.24 ms | loss 0.03473
| epoch   2 |    70/   90 batches | lr 0.001000 | 111.78 ms | loss 0.06833
| epoch   2 |    80/   90 batches | lr 0.001000 | 110.94 ms | loss 0.06185
| epoch   2 |    90/   90 batches | lr 0.001000 | 106.36 ms | loss 0.08910
data_source shape: torch.Size([5784, 2, 20, 36])
output shape: torch.Size([20, 1, 36])
output[[0]].shape: torch.Size([1, 1, 36])
output[:-1].shape: torch.Size([19, 1, 36])
truth shape: torch.Size([5803, 36])
test_result shape: torch.Size([5803, 36])
output truth shape: (5803, 36)
output test_result shape: (5803, 36)
test_result[0].shape, type (36,) float64
test_result.shape, type (5803, 36) float64
loss shape:  (5803, 36)
output_df shape: (5803, 108)
---------------------------------
start SVM
---------------------------------
精度为0.9896623018607856
precision:  1.0  recall:  0.5774647887323944  acc:  0.9948302602102361  f1:  0.7321428571428571
混淆矩阵:
 [[5732    0]
 [  30   41]]
-----------------------------------------------------------------------------------------
| end of epoch   2 | time: 37.97s | valid loss 8.31958
-----------------------------------------------------------------------------------------
save successfully
| epoch   3 |    10/   90 batches | lr 0.001000 | 128.40 ms | loss 0.04893
| epoch   3 |    20/   90 batches | lr 0.001000 | 117.51 ms | loss 0.05234
| epoch   3 |    30/   90 batches | lr 0.001000 | 119.70 ms | loss 0.03720
| epoch   3 |    40/   90 batches | lr 0.001000 | 117.84 ms | loss 0.03746
| epoch   3 |    50/   90 batches | lr 0.001000 | 118.63 ms | loss 0.03441
| epoch   3 |    60/   90 batches | lr 0.001000 | 116.90 ms | loss 0.02876
| epoch   3 |    70/   90 batches | lr 0.001000 | 113.59 ms | loss 0.06338
| epoch   3 |    80/   90 batches | lr 0.001000 | 112.47 ms | loss 0.05741
| epoch   3 |    90/   90 batches | lr 0.001000 | 110.19 ms | loss 0.08320
data_source shape: torch.Size([5784, 2, 20, 36])
output shape: torch.Size([20, 1, 36])
output[[0]].shape: torch.Size([1, 1, 36])
output[:-1].shape: torch.Size([19, 1, 36])
truth shape: torch.Size([5803, 36])
test_result shape: torch.Size([5803, 36])
output truth shape: (5803, 36)
output test_result shape: (5803, 36)
test_result[0].shape, type (36,) float64
test_result.shape, type (5803, 36) float64
loss shape:  (5803, 36)
output_df shape: (5803, 108)
---------------------------------
start SVM
---------------------------------
精度为0.9875947622329428
precision:  1.0  recall:  0.49295774647887325  acc:  0.9937963122522833  f1:  0.660377358490566
混淆矩阵:
 [[5732    0]
 [  36   35]]
-----------------------------------------------------------------------------------------
| end of epoch   3 | time: 45.09s | valid loss 7.62966
-----------------------------------------------------------------------------------------
save successfully
| epoch   4 |    10/   90 batches | lr 0.001000 | 130.78 ms | loss 0.04548
| epoch   4 |    20/   90 batches | lr 0.001000 | 114.93 ms | loss 0.05062
| epoch   4 |    30/   90 batches | lr 0.001000 | 110.17 ms | loss 0.03569
| epoch   4 |    40/   90 batches | lr 0.001000 | 115.62 ms | loss 0.03530
| epoch   4 |    50/   90 batches | lr 0.001000 | 113.55 ms | loss 0.03214
| epoch   4 |    60/   90 batches | lr 0.001000 | 116.92 ms | loss 0.02646
| epoch   4 |    70/   90 batches | lr 0.001000 | 120.77 ms | loss 0.06189
| epoch   4 |    80/   90 batches | lr 0.001000 | 118.39 ms | loss 0.05533
| epoch   4 |    90/   90 batches | lr 0.001000 | 107.41 ms | loss 0.08274
data_source shape: torch.Size([5784, 2, 20, 36])
output shape: torch.Size([20, 1, 36])
output[[0]].shape: torch.Size([1, 1, 36])
output[:-1].shape: torch.Size([19, 1, 36])
truth shape: torch.Size([5803, 36])
test_result shape: torch.Size([5803, 36])
output truth shape: (5803, 36)
output test_result shape: (5803, 36)
test_result[0].shape, type (36,) float64
test_result.shape, type (5803, 36) float64
loss shape:  (5803, 36)
output_df shape: (5803, 108)
---------------------------------
start SVM
---------------------------------
Traceback (most recent call last):
  File "train.py", line 150, in <module>
    main(args)
  File "train.py", line 115, in main
    val_loss = plot_and_loss(model, val_data, epoch, criterion, input_window, scaler, args.dim, labels)
  File "D:\PythonProject\Time_series_anomaly_detection\utils\plot_and_loss.py", line 133, in plot_and_loss
    clf = svm_c(loss_value, labels)
  File "D:\PythonProject\Time_series_anomaly_detection\utils\plot_and_loss.py", line 193, in svm_c
    clf = grid.fit(x_train, y_train)
  File "D:\miniconda\envs\pytorch\lib\site-packages\sklearn\model_selection\_search.py", line 891, in fit
    self._run_search(evaluate_candidates)
  File "D:\miniconda\envs\pytorch\lib\site-packages\sklearn\model_selection\_search.py", line 1768, in _run_search
    self.param_distributions, self.n_iter, random_state=self.random_state
  File "D:\miniconda\envs\pytorch\lib\site-packages\sklearn\model_selection\_search.py", line 851, in evaluate_candidates
    enumerate(candidate_params), enumerate(cv.split(X, y, groups))
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\parallel.py", line 1056, in __call__
    self.retrieve()
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\parallel.py", line 935, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "D:\miniconda\envs\pytorch\lib\site-packages\joblib\_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "D:\miniconda\envs\pytorch\lib\concurrent\futures\_base.py", line 430, in result
    self._condition.wait(timeout)
  File "D:\miniconda\envs\pytorch\lib\threading.py", line 296, in wait
    waiter.acquire()
KeyboardInterrupt