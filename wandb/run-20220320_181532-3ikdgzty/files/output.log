
| epoch   1 |    10/  173 batches | lr 0.001000 | 245.70 ms | loss 0.61056
| epoch   1 |    20/  173 batches | lr 0.001000 | 217.56 ms | loss 0.18348
| epoch   1 |    30/  173 batches | lr 0.001000 | 217.93 ms | loss 0.12973
| epoch   1 |    40/  173 batches | lr 0.001000 | 218.38 ms | loss 0.12198
| epoch   1 |    50/  173 batches | lr 0.001000 | 224.51 ms | loss 0.11558
| epoch   1 |    60/  173 batches | lr 0.001000 | 215.27 ms | loss 0.11425
| epoch   1 |    70/  173 batches | lr 0.001000 | 221.99 ms | loss 0.11632
| epoch   1 |    80/  173 batches | lr 0.001000 | 217.22 ms | loss 0.11818
| epoch   1 |    90/  173 batches | lr 0.001000 | 216.04 ms | loss 0.11601
| epoch   1 |   100/  173 batches | lr 0.001000 | 219.19 ms | loss 0.11109
| epoch   1 |   110/  173 batches | lr 0.001000 | 221.57 ms | loss 0.11325
| epoch   1 |   120/  173 batches | lr 0.001000 | 227.21 ms | loss 0.11305
| epoch   1 |   130/  173 batches | lr 0.001000 | 219.04 ms | loss 0.11470
| epoch   1 |   140/  173 batches | lr 0.001000 | 219.32 ms | loss 0.11444
| epoch   1 |   150/  173 batches | lr 0.001000 | 222.08 ms | loss 0.11569
| epoch   1 |   160/  173 batches | lr 0.001000 | 222.51 ms | loss 0.10967
| epoch   1 |   170/  173 batches | lr 0.001000 | 221.44 ms | loss 0.11255
data_source shape: torch.Size([11084, 2, 100, 6])
output shape: torch.Size([100, 1, 6])
output[[0]].shape: torch.Size([1, 1, 6])
output[:-1].shape: torch.Size([99, 1, 6])
truth shape: torch.Size([11183, 6])
test_result shape: torch.Size([11183, 6])
output truth shape: (11183, 6)
output test_result shape: (11183, 6)
test_result[0].shape, type (6,) float64
test_result.shape, type (11183, 6) float64
loss shape:  (11183, 6)
---------------------------------
start SVM
---------------------------------
精度为0.8050961108627627
precision:  0.11792177466433158  recall:  0.7769230769230769  acc:  0.8596977555217741  f1:  0.2047643182970096
-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 236.71s | valid loss 0.11243
-----------------------------------------------------------------------------------------
save successfully
| epoch   2 |    10/  173 batches | lr 0.001000 | 240.62 ms | loss 0.11880
| epoch   2 |    20/  173 batches | lr 0.001000 | 216.03 ms | loss 0.10807
| epoch   2 |    30/  173 batches | lr 0.001000 | 215.26 ms | loss 0.11253
| epoch   2 |    40/  173 batches | lr 0.001000 | 222.51 ms | loss 0.11434
| epoch   2 |    50/  173 batches | lr 0.001000 | 218.43 ms | loss 0.10994
| epoch   2 |    60/  173 batches | lr 0.001000 | 217.96 ms | loss 0.10995
| epoch   2 |    70/  173 batches | lr 0.001000 | 222.20 ms | loss 0.11317
| epoch   2 |    80/  173 batches | lr 0.001000 | 220.17 ms | loss 0.11506
| epoch   2 |    90/  173 batches | lr 0.001000 | 221.74 ms | loss 0.11328
| epoch   2 |   100/  173 batches | lr 0.001000 | 238.95 ms | loss 0.10879
| epoch   2 |   110/  173 batches | lr 0.001000 | 263.73 ms | loss 0.11082
| epoch   2 |   120/  173 batches | lr 0.001000 | 303.40 ms | loss 0.11130
| epoch   2 |   130/  173 batches | lr 0.001000 | 270.88 ms | loss 0.11277
| epoch   2 |   140/  173 batches | lr 0.001000 | 289.46 ms | loss 0.11287
| epoch   2 |   150/  173 batches | lr 0.001000 | 225.01 ms | loss 0.11376
| epoch   2 |   160/  173 batches | lr 0.001000 | 215.79 ms | loss 0.10789
| epoch   2 |   170/  173 batches | lr 0.001000 | 213.34 ms | loss 0.11114
data_source shape: torch.Size([11084, 2, 100, 6])
output shape: torch.Size([100, 1, 6])
output[[0]].shape: torch.Size([1, 1, 6])
output[:-1].shape: torch.Size([99, 1, 6])
truth shape: torch.Size([11183, 6])
test_result shape: torch.Size([11183, 6])
output truth shape: (11183, 6)
output test_result shape: (11183, 6)
test_result[0].shape, type (6,) float64
test_result.shape, type (11183, 6) float64
loss shape:  (11183, 6)
---------------------------------
start SVM
---------------------------------
精度为0.8404112650871703
precision:  0.1364247311827957  recall:  0.7807692307692308  acc:  0.8799964231422696  f1:  0.2322654462242563
-----------------------------------------------------------------------------------------
| end of epoch   2 | time: 174.33s | valid loss 0.11128
-----------------------------------------------------------------------------------------
save successfully
| epoch   3 |    10/  173 batches | lr 0.001000 | 241.31 ms | loss 0.11743
| epoch   3 |    20/  173 batches | lr 0.001000 | 250.07 ms | loss 0.10678
Traceback (most recent call last):
  File "train.py", line 150, in <module>
    main(args)
  File "train.py", line 111, in main
    train(train_data, input_window, model, optimizer, criterion, scheduler, epoch, batch_size)
  File "D:\PythonProject\Time_series_anomaly_detection\utils\train.py", line 19, in train
    loss.backward()
  File "D:\miniconda\envs\pytorch\lib\site-packages\torch\_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "D:\miniconda\envs\pytorch\lib\site-packages\torch\autograd\__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt